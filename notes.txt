goals : 

  finish install script, modify yaml (disks) at appropriate point
  fix update so that I can update local system and modify boot to current. Also make sure it uses proxy, not wan

  create test-maps for functions, basis functions have -t for basis checking other functions (higher up the stack)
  maps are json, ie { 3, "args", "this/is/a/path", "this/is/output" }, json maps can be stored in xml, alongside the include file.
  xml-map files will utilize 'jq' + xml query tools for commandline.
  https://stackoverflow.com/questions/1955505/parsing-json-with-unix-tools




<span style="color:red">(not yet implemented) 
  (concept-btrfs) ./deploy build=plasma work=btrfs_mount/subvol\
  (concept-ext4,...) ./deploy build=plasma work=/path/to/rootfs deploy </span>

[ BACKEND SPEC. | BUILD SERVER ]  :: { to reference pkgmx.sh & profile.sh for profiling machines and maintaining bin_pkgs }

  ?       TIME MACHINE BASED REPO REFERENCE (requires metadata build, snapshots...) - GOAL to hit year 2000 /w distfile fetcher

  ?       CUSTOM STAGE 3 GENERATOR FOR TIME MACHINE BUILDS

  ?       PER USE FLAG, PER VERSION, PACKAGE BUILDER (USE SUBVOLs or DATASET) ... BTRFS PROBABLY BEST SUITED FOR TREEING OUT VARIABLE CASE BUILDS

  ?       BUG TRACKING (FROM GENTOO.ORG) & LOCALLY GENERATED BUG REPORTING+LOGGING FACILITIES

  ?       AUTOMATED WORK AROUNDS (FIND WAYS TO TEST FOR WORK AROUNDS, AUTOMATICALLY, SAVE GOOD CATCH AS A PATCH, AND A BUG, W/ CLASS TYPE respecting the PATCH FORMULATION) [pluggable]

  - web serves are too inconsistent and will require 'tests'/QC after syncs/pulls (hashs most likely)

  - NOW MIGRATING TO DYNAMIC HOSTS, etc/hosts will be patched, soon a respectful dhcp/subnet-friendly/dns solution will be required for the dom.0 but before this, i will need to build NEXUS up.

  * VERIFY MODULES ARE INSTALLED ON INSTALL.

  - skipping modules missing program (networking)
  - adsl/pppoe
  - br2684ctl
  - atmsigd/clipe
  - netplugd
  - ifplugd
  - ipppd
  - iwoconfig
  - firewald
  - udhcpc/busybox
  - pump
  - dhclient

  - automated issue tracking / bug reporting.

  - need to validate *.pkgs/dryrun before building in :: deploy. Some packages might not exist and will break the deployment

  - update needs to utilize 'profiles' in order to preserve profile specific config data 




  - kernel modules are wrongly installed during deployment or update or install. figure it out




  - it appears some snapshots (gentoo) are not loading properly, might need to test and mask. (http/etc-hosts file)

  - I seriously need a way to test package/profile combos and check for useflags/masking issues.

  x

  - build list of dependencies for this platform, add pkgcore.

  - add meta commands to f/w (ex. fw.meta + fw.sh = tables) the meta file maps out invalid packet specs, and host configs. That said, the current intent to recurse a form of networking through all layers of the network stack, should be attempted, and then modeled afterwards, w/ in the meta config. 

  - better granularity over profile versions, and then move common in to specific versions, then be able to understand the version when patching w/ specific sets. 

  x
  
  - create an autopatcher script for updating servers, and software patches (basically a portage + sys patch hooked to a server update or emerge --update)

  - centralize the hosting-config for pkg/bld services with new host scripts. I need to be able to turn towards public or private, and between private servers with in one edit.

  - sanitize mget - stream methods, need to check this one closely for most/close to all cases.
  
  x

  x




  - umount is trying to mount non-existant mounts. (invalid buildup procedure)





  x


  - figure out why fstab is not loading up the pool/swap [install]





  ?
  ?
  ?
  
  x
  x

  add boot resolutions to the [profile], to be patched after deploy-system-[update], alongside the rest of the profile packages/configs.

  x
  x
  x

  add wpa_supplicant, and auto spawn for wireless, given an adapter, spawn can be used in fw meta package

      wireless = always LAN
      
      wired = check ip range, LAN = private space ; WAN = public space

      wireguard takes in all LAN + lo + default route

      virbr0 goes to WAN / static routes point to WAN-NET

      wireguard goes to WAN IP, need to define routing exchange


  IF A PACKAGE FAILS TO BUILD DURING DEPLOY, IT MUST BE:
    LOGGED
    & REPORTED 

  x
  x  

  ** META PACKAGE, FW NOTES:

    systemd-resolved disabled

    wireguard routing/instantiation/dependency installs

    openrc/systemd installer (./install.sh)

    assets: bastionX.sh, as (/etc/init.d - service) || (systemd unit files + sbin)

    dependency chains for net-tools & ipcalc

    bastionX, accounts for dynamic virttual bridging, and 1 wg interface, domain specific, for the machine its on 


  * bring vscode key, in to meta package, take out of default for desktop profiles.

  !!!!! move lxd-prep in to lxd meta package. virbr0 will be for libvirt, autosensed by fw, virbr1 reserved for lxd, autosensed.

  !!!!! run a service check (base services) w/ update (command [services]) on command line ./update.sh

  !!!!! NEED TO MOVE SCRIPT BASE DIR to project dir, and then prefix with bash, then move esync over to ./config, include stays in ./bash, along with mget, mirror moves to ./config --refactor

  //unmount.exe for unmounting chroots...

    x

  Prospect - profile.sh : ./profile.sh profile=sub.domain.tld work={pool/set}.../ bootpart=/dev/efi_part

  profile.sh - takes in the important settings for a given environment, needs to be modular, including the boot env, and stores them in ./profile/TLD/DOMAIN/SUB
  granularity is only down to subdomain, as this is meant for machines only,  not apps/services inside a cluster like kubernetes,  docker or lxd. 

  TBD.

  domain tools : have a config file for the domain name/server ips, manage all references through a single command/config file.

  x...

  create build services, to serve as an alternative for distfiles complete sync, where only relavent packages will be installed in to distfiles over sshfs/bind mounts. Build service to feature, binpkg versioning, per kernel, per glibc, ... use the local zfs on VM to snapshot per versioning, client versioning to use this as a basis, for it's own.

  g3 clones from g2 snapshot_versioning, from g1@safe.

  better snapshot management, especially for cloning to profile build services

  BTRFS INTEGRATION !!!

  kernel upgrade service, from upgrade script. (local machine upgrade in to kernel tree)

  add zfs key management, before dom-0 ca, must be able to integrate upwards/scale in to dom.0/ca

  x 
  x - partially resolved

  x
  x

  find a way to hash patched server directories, log output, and report differences

  bundles : need meta packages for things like libvirt, to include patches for /etc ... bundles can be placed in /bundle/call/*.pkgs;*.patches/rootdir/...

  x ... live environments/isos are not supported by refind, directly, would require separate gpt partitions, memtest added.
  x
  x

  add support for inclusion of arm+ builds { binpkgs | releases | ... }

  !!!!!! Add bastion4 to rc-conf.d :: new code in to bastion, wait for adapters, and timeout. Perhaps run as a daemon.
  MODIFY BASTION TO ASSOCIATE VIRTUAL BRIDGES, AUTOMATING FIND WAN ADAPTERS or LAN (based on Private Network Space/ vs WAN, possibly use conf.d/net ...) Need 

  x

  !!!!!!! verify nproc works on [update] ... needs to to be addressed, per boot (rc-conf.d) ... install to drive in live env, update not on live image, but to new host, and associate with boot medium. Live env=boot disk.

  CIK ---> live rescue image [boot] ---> install to host disk, update w/ CIK in computer, CIK adds a reference to the host system, rinse and repeat and you have one key for many systems.
  ON A multi-host system, the basis pool can facilitate many different CIK installs, each install is a profile, with a domain name, this is stored on the associated domain 0 for a given domain.
  Any time a CIK boots a host or rescue image, the initramfs can be swapped out for one with new keys, a rescue volume can have new keys loaded to it (post boot env). This is handled completely 
  transparently via ssh. Installs require network connectivity, or a an install derived from the rescue disk itself. 32 GB can facilitate up to two desktop systems, (20GB) and a 8GB EFI partition.
  CIK's up to 250GB can handle many different profiles, and more functionality perhaps, as well as maybe a roaming user space (volume). Disks up to 2TB can serve as a pop in domain 0, or perhaps even 
  another domain component/application service. See Dom.N / Dom.0. Every Dom. is a Virtual Machine, routed through virtual networking, interlinked via encrypted trunks. Every Dom provides Container Application Support.

  check if modules deployed during install (only)

  x
  x

  x

  x

  x

  libvirt is not patched. .... PROFILE ASSERT

  !!!!!!     world file, will be over written by portage map, need to rethink ...

  no network profiling ....

  x

  x

  qemu missing : swtpm + usermod-utilities, ssh enabled thru profile ... profile+services capture ... profile+key mngmt/capture

  x

  network addressing / configuration can take place using auto negotiation, utilizing certs, vpn-tun/tap's and dhcp. vpn's require a general client certificate + a private key/auth mechanism

  get rid of @safe snapshot prior to deployment, deployment assumes initialization ...

  !!!!!!!!!!!!!!!!!!!! all ip address scheme - dom.zero 10.0.0.1 (dns resolve pt) .: universal naming convention for the distribution hub, prod.dom.zero and dev.dom.zero
                      all other resolve points will be, if neccessary captured by a patch_sys -> /etc/hosts, for which the rest of the system can elate across the network through name services.

  install will assume the originating dataset's key and mount points, also install does not have a schema build system, where as multiple disks and custom properties cannot be asserted conveniently. 

  Should I give deployment an option for remote destination ? 

  Work+Verify I can install to an existing ZFS (only) pool, this skips disk initialization, setup, but requires a new boot entry

  Needs new_host.sh script to adapt new hardware (make.conf + networking) ; script is run 

  Needs dynamic keylocation assertion @ end of deploy.sh ... eventually tie in to CA/PKI/OLDAP w/ custom prebuilt initramfs 

  x

  x

  x

  need to start using signed packages !

  sequencing snapshots, versioning and updates.

  ....................need to auto configure zfs-loop for swap_memory+autofs.

  x

  x

  pkg signing keys + kernel_source (signing_module_key) needs to reside on Dom0

  EFI_signing , from safe_image, ... custom_key + appropriated_HW + procedure + thumb drive it seems ...
  try to find a way to assign keys from live environment (automated) 

  consider FUSE-encrypted file systems for cloud or publicly facing appliances. per process/user

  conversion script for pkg to signed package format : GPKG

  patch for roaming profiles ... also zsh.history_db integration.

  -user roaming (sync -OLDAP, ... ?)

  -machine roaming (snapshot w/ customization) .. think crypto_ignition_key<>

  -need a suplimentary dataset || subvol || partition setup for things like home. ... supplimentary configs ? (probably best for after GUI)

  :: perhaps a SSO - CIK, w/ an initramfs which overlays the roaming machine over a default, then snaps from r-o to rw g3 dataset (single boot)

 - dom0 needs to run on UTC

pkg-mx :

  use cases: REBUILD_MISSING_PKGS ; DELETE_REDUNDANT_PACKAGES ; MULTI_VARIATE_USE_BUILD ; LOGGING_FACILITY

  need utility for examining imposed uses flags, and list of packages against binpkg repo Packages file.
  this utility can be used to filter out already built packages satisfying use/version for missing bin package use case.

  need a filter for sweeping through Packages in order to find redundant entries and their associated bin pkg, delete if not 'pretend'.

  utility for rebuilding any package, with all combinations of use flags
    
  logging facility for catching broken package builds during audit.


Supplimental infrastructure

  LXD @ Boot + BASIC DOM-N bridging + auto configuring firewall

oddities

  x
  sysop/root profiles do not have a good gnome or plasma preferences, for the terminal, or desktop, etc...


portage/

  *infrastructure\
  distfiles       # install data\
  snapshots       # portage tree snapshots, daily or every other daily\
  repos           # repo portage tree, THE most up todate sync\
  releases        # sys releases repo, install medium / stage3\
  binpkgs         # binpkg repo
  
  *g2d\
  patchfiles      # specific config files (etc/...)\
  packages        # package and conf files, per profile, such as hardened, selinux, gnome, gnome/systemd\
  profiles        # configs for real/virtual machines, host/domain name dependent\
  kernels         # repo for current and depricated kernels


working on:

  btrfs+xfs+ext4 integration [ install.sh ]
  UPDATE deploy script, modernize w/ mget() on some ops, like install_kernel


needs:

  update function
  
  review install function
  further updates per f/s and schema added

  network adapter mapping (yaml...?)


CONCEPT:

  DOM-0 / 

    plug in to any machine, auto associates, connects to cloud VPN, auto updates/syncs.
    requirement - decent machine which can host a DOM-0 VM. 
    SIZE ... needs to be at least 8TB


#
##  INSTALLER NOTES
#
#   requires:
#
#     off-premises kernel repository (~1TB+)
#     off-premises user repository (NAS,remote mount,NFSv4?)
#     off-premises standardized-root directory 
#     off-premises patchfiles (<100MB)
#     off-premises binpkgs--backup
#     generator for gentoo git repos  
#
#     g2deploy repository
#
#       linkage script, that pulls in repos
#       
#       create baseline snapshot, replaced monthly; periodic backups must be done on File Servers.